{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ss9WR_zbQELO"
   },
   "source": [
    "# Практическое задание 3\n",
    "\n",
    "# Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sB3vM2GfQELQ"
   },
   "source": [
    "## Введение\n",
    "\n",
    "### Постановка задачи\n",
    "\n",
    "В этом задании вы будете решать задачу извлечения именованных сущностей (Named Entity Recognition) - одну из самых распространенных в NLP наряду с задачей текстовой классификации.\n",
    "\n",
    "Данная задача заключается в том, что нужно классифицировать каждое слово / токен на предмет того, является ли оно частью именованной сущности (сущность может состоять из нескольких слов / токенов) или нет.\n",
    "\n",
    "Например, мы хотим извлечь имена и названия организаций. Тогда для текста\n",
    "\n",
    "    Yan    Goodfellow  works  for  Google  Brain\n",
    "\n",
    "модель должна извлечь следующую последовательность:\n",
    "\n",
    "    B-PER  I-PER       O      O    B-ORG   I-ORG\n",
    "\n",
    "где префиксы *B-* и *I-* означают начало и конец именованной сущности, *O* означает слово без тега. Такая префиксная система (*BIO*-разметка) введена, чтобы различать последовательные именованные сущности одного типа.\n",
    "Существуют и другие типы разметок, например *BILUO*, но в рамках данного практического задания сфокусируемся имеено на *BIO*.\n",
    "\n",
    "Решать NER задачу мы будем на датасете CoNLL-2003 с использованием рекуррентных сетей и моделей на базе архитектуры Transformer.\n",
    "\n",
    "### Библиотеки\n",
    "\n",
    "Основные библиотеки:\n",
    " - [PyTorch](https://pytorch.org/)\n",
    " - [Transformers](https://github.com/huggingface/transformers)\n",
    " \n",
    "### Данные\n",
    "\n",
    "Данные лежат в архиве, который состоит из:\n",
    "\n",
    "- *train.tsv* - обучающая выборка. В каждой строке записаны: <слово / токен>, <тэг слова / токена>\n",
    "\n",
    "- *valid.tsv* - валидационная выборка, которую можно использовать для подбора гиперпарамеров и замеров качества. Имеет идентичную с train.tsv структуру.\n",
    "\n",
    "- *test.tsv* - тестовая выборка, по которой оценивается итоговое качество. Имеет идентичную с train.tsv структуру.\n",
    "\n",
    "Скачать данные можно здесь: [ссылка](https://github.com/dayyass/msu_task_3_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "S5BCB1EfQan1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.21.6\n",
      "  Downloading numpy-1.21.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
      "     |████████████████████████████████| 15.9 MB 2.4 MB/s            \n",
      "\u001b[?25hCollecting scikit-learn==1.0.2\n",
      "  Downloading scikit_learn-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
      "     |████████████████████████████████| 26.5 MB 1.8 MB/s            \n",
      "\u001b[?25hCollecting tensorboard==2.9.0\n",
      "  Downloading tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n",
      "     |████████████████████████████████| 5.8 MB 2.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: torch==1.12.1 in /home/dmitry/PycharmProjects/DML/venv/lib/python3.10/site-packages (1.12.1)\n",
      "Collecting tqdm==4.64.0\n",
      "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "     |████████████████████████████████| 78 kB 1.9 MB/s            \n",
      "\u001b[?25hCollecting transformers==4.21.1\n",
      "  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n",
      "     |████████████████████████████████| 4.7 MB 1.2 MB/s            \n",
      "\u001b[?25hCollecting joblib>=0.11\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting scipy>=1.1.0\n",
      "  Using cached scipy-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.7 MB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/dmitry/PycharmProjects/DML/venv/lib/python3.10/site-packages (from tensorboard==2.9.0) (60.2.0)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.14.1-py2.py3-none-any.whl (175 kB)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard==2.9.0) (2.25.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/dmitry/PycharmProjects/DML/venv/lib/python3.10/site-packages (from tensorboard==2.9.0) (0.37.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/lib/python3/dist-packages (from tensorboard==2.9.0) (1.30.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/lib/python3/dist-packages (from tensorboard==2.9.0) (3.12.4)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.12.1) (4.3.0)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from transformers==4.21.1) (3.6.0)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers==4.21.1) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from transformers==4.21.1) (21.3)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2022.10.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "     |████████████████████████████████| 6.6 MB 2.2 MB/s            \n",
      "\u001b[?25hCollecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.9.0) (1.16.0)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Using cached MarkupSafe-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.9.0) (3.2.0)\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, cachetools, tqdm, requests-oauthlib, numpy, MarkupSafe, google-auth, werkzeug, tokenizers, threadpoolctl, tensorboard-plugin-wit, tensorboard-data-server, scipy, regex, markdown, joblib, huggingface-hub, google-auth-oauthlib, absl-py, transformers, tensorboard, scikit-learn\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.4\n",
      "    Uninstalling numpy-1.23.4:\n",
      "      Successfully uninstalled numpy-1.23.4\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 2.0.1\n",
      "    Not uninstalling markupsafe at /usr/lib/python3/dist-packages, outside environment /home/dmitry/PycharmProjects/DML/venv\n",
      "    Can't uninstall 'MarkupSafe'. No files were found to uninstall.\n",
      "Successfully installed MarkupSafe-2.1.1 absl-py-1.3.0 cachetools-5.2.0 google-auth-2.14.1 google-auth-oauthlib-0.4.6 huggingface-hub-0.11.0 joblib-1.2.0 markdown-3.4.1 numpy-1.21.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 regex-2022.10.31 requests-oauthlib-1.3.1 rsa-4.9 scikit-learn-1.0.2 scipy-1.9.3 tensorboard-2.9.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 threadpoolctl-3.1.0 tokenizers-0.12.1 tqdm-4.64.0 transformers-4.21.1 werkzeug-2.2.2\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/dmitry/PycharmProjects/DML/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    " !pip install numpy==1.21.6 scikit-learn==1.0.2 tensorboard==2.9.0 torch==1.12.1 tqdm==4.64.0 transformers==4.21.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Thidpb9qQELS",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter, defaultdict, namedtuple\n",
    "from typing import Tuple, List, Dict, Any\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AiDlmbY2QELT"
   },
   "source": [
    "Зафиксируем seed для воспроизводимости результатов (желательно делать **всегда**!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "yt3ISg3aQELU",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def set_global_seed(seed: int) -> None:\n",
    "    \"\"\"\n",
    "    Set global seed for reproducibility.\n",
    "    \"\"\"\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "set_global_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhIg0ZBzQELV"
   },
   "source": [
    "Проинициализируем device (CPU / GPU) на котором будем работать (желательно **GPU**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rboLOv95QELV",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UW16ryFIQELW"
   },
   "source": [
    "Здесь и далее проинициализируем *tensorboard* для логгирования метрики в процессе обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6O7Y8hReTODp",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 15464."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4k3Nhd3IQELY"
   },
   "source": [
    "## Часть 1. Подготовка данных (4 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qYjOMuPQELY"
   },
   "source": [
    "Первым делом нам нужно считать данные. Давайте напишем функцию, которая на вход принимает путь до одного из conll-2003 файла и возвращает два списка:\n",
    "- список списков слов / токенов (и соответствующий ему)\n",
    "- список списков тегов\n",
    "\n",
    "P.S. Сделаем данную функцию более гибкой, подавая на вход еще булеву переменную, считываем ли мы данные в *lowercase* или нет.\n",
    "\n",
    "**Задание. Реализуйте функцию read_conll2003.** **<font color='red'>(1 балл)</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "wQdCfX2OQELZ",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "def read_conll2003(\n",
    "    path: str,\n",
    "    lower: bool = True,\n",
    ") -> Tuple[List[List[str]], List[List[str]]]:\n",
    "    \"\"\"\n",
    "    Prepare data in CoNNL like format.\n",
    "    \"\"\"\n",
    "\n",
    "    token_seq = []\n",
    "    label_seq = []\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    file = open(path, \"r\")\n",
    "    if file:\n",
    "        lines = csv.reader(file, delimiter='\\t', quotechar=None)\n",
    "        tmp_1 = []\n",
    "        tmp_2 = []\n",
    "        for line in lines:\n",
    "            if len(line) > 0:\n",
    "                if lower:\n",
    "                    tmp_1 += [line[0].lower()]\n",
    "                else:\n",
    "                    tmp_1 += [line[0]]\n",
    "                tmp_2 += [line[1]]\n",
    "            else:\n",
    "                token_seq += [tmp_1]\n",
    "                label_seq += [tmp_2]\n",
    "                tmp_1 = []\n",
    "                tmp_2 = []\n",
    "    file.close()\n",
    "    return token_seq, label_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYm8xEvFQELb"
   },
   "source": [
    "Считаем все три файла:\n",
    "- *train.tsv*\n",
    "- *valid.tsv*\n",
    "- *test.tsv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-inr1BPgQELb",
    "outputId": "125203fe-c32e-459d-e659-d1a999712147",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_token_seq, train_label_seq = read_conll2003(\"data/train.tsv\")\n",
    "valid_token_seq, valid_label_seq = read_conll2003(\"data/valid.tsv\")\n",
    "test_token_seq, test_label_seq = read_conll2003(\"data/test.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOoNc1VUQELc"
   },
   "source": [
    "Посмотрим на то, что мы получили:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HK8AcwWGQELd",
    "outputId": "d949fff7-3fb9-4e3e-c2fa-853d449f8314",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eu\tB-ORG\n",
      "rejects\tO\n",
      "german\tB-MISC\n",
      "call\tO\n",
      "to\tO\n",
      "boycott\tO\n",
      "british\tB-MISC\n",
      "lamb\tO\n",
      ".\tO\n"
     ]
    }
   ],
   "source": [
    "for token, label in zip(train_token_seq[0], train_label_seq[0]):\n",
    "    print(f\"{token}\\t{label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K8SqDeMJjF3Y",
    "outputId": "4939b43d-4fe6-4125-a383-6cb89b573d4e",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cricket\tO\n",
      "-\tO\n",
      "leicestershire\tB-ORG\n",
      "take\tO\n",
      "over\tO\n",
      "at\tO\n",
      "top\tO\n",
      "after\tO\n",
      "innings\tO\n",
      "victory\tO\n",
      ".\tO\n"
     ]
    }
   ],
   "source": [
    "for token, label in zip(valid_token_seq[0], valid_label_seq[0]):\n",
    "    print(f\"{token}\\t{label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ddFE7p5kjF_p",
    "outputId": "b000a8f1-49b9-4022-905e-78077ee2e666",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soccer\tO\n",
      "-\tO\n",
      "japan\tB-LOC\n",
      "get\tO\n",
      "lucky\tO\n",
      "win\tO\n",
      ",\tO\n",
      "china\tB-PER\n",
      "in\tO\n",
      "surprise\tO\n",
      "defeat\tO\n",
      ".\tO\n"
     ]
    }
   ],
   "source": [
    "for token, label in zip(test_token_seq[0], test_label_seq[0]):\n",
    "    print(f\"{token}\\t{label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BZ4Go3IXfDit",
    "outputId": "f5d3dc81-6aa2-4311-8168-b0c9dc0976d0",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тесты пройдены!\n"
     ]
    }
   ],
   "source": [
    "assert len(train_token_seq) == len(train_label_seq), \"Длины тренировочных token_seq и label_seq не совпадают, ошибка в функции read_conll2003\"\n",
    "assert len(valid_token_seq) == len(valid_label_seq), \"Длины валидационных token_seq и label_seq не совпадают, ошибка в функции read_conll2003\"\n",
    "assert len(test_token_seq) == len(test_label_seq), \"Длины тестовых token_seq и label_seq не совпадают, ошибка в функции read_conll2003\"\n",
    "\n",
    "assert train_token_seq[0] == ['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.'], \"Ошибка в тренировочном token_seq\"\n",
    "assert train_label_seq[0] == ['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O'], \"Ошибка в тренировочном label_seq\"\n",
    "\n",
    "assert valid_token_seq[0] == ['cricket', '-', 'leicestershire', 'take', 'over', 'at', 'top', 'after', 'innings', 'victory', '.'], \"Ошибка в валидационном token_seq\"\n",
    "assert valid_label_seq[0] == ['O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], \"Ошибка в валидационном label_seq\"\n",
    "\n",
    "assert test_token_seq[0] == ['soccer', '-', 'japan', 'get', 'lucky', 'win', ',', 'china', 'in', 'surprise', 'defeat', '.'], \"Ошибка в тестовом token_seq\"\n",
    "assert test_label_seq[0] == ['O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O'], \"Ошибка в тестовом label_seq\"\n",
    "\n",
    "print(\"Тесты пройдены!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j96zKo6PQELd"
   },
   "source": [
    "Датасет CoNLL-2003 представлен в виде разметки **BIO**, где лейбл:\n",
    "- *B-{label}* - начало сущности *{label}*\n",
    "- *I-{label}* - продолжение сущности *{label}*\n",
    "- *O* - отсутсвие сущности\n",
    "\n",
    "Также существует другие разметки последовательностей, например **BILUO**. Подробнее с разметками можно ознакомится во вспомогательном ноутбуке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SVL4USbQELe"
   },
   "source": [
    "### Подготовка словарей\n",
    "\n",
    "Чтобы обучать нейронную сеть, мы будем использовать два отображения:\n",
    "- {**token**}→{**token_idx**}: соответствие между словом / токеном и строкой в *embedding* матрице (начинается с 0);\n",
    "- {**label**}→{**label_idx**}: соответствие между тегом и уникальным индексом (начинается с 0);\n",
    "\n",
    "Теперь нам необходимо реализовать две функции:\n",
    "- get_token2idx\n",
    "- get_label2idx\n",
    "\n",
    "которые будут возвращать соответствующие словари.\n",
    "\n",
    "P.S. token2idx словарь должен также содержать специальные токены:\n",
    "- `<PAD>` - спецтокен для паддинга, так как мы собираемся обучать модели батчами\n",
    "- `<UNK>` - спецтокен для обработки слов / токенов, которых нет в словаре (актуально для инференса)\n",
    "\n",
    "Давайте для удобства дадим им idx 0 и 1 соответственно.\n",
    "\n",
    "P.P.S. В get_token2idx можно также добавить параметр *min_count*, который будет включать только слова превышающие определенную частоту."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOnc3UHpQELf"
   },
   "source": [
    "Сначала соберем:\n",
    "- token2cnt - словарь из уникального слова / токена в количество это слова / токена в тренировочной выборке (важно, что только в тренировочной!)\n",
    "- label_set - список из уникальных тегов\n",
    "\n",
    "P.S. Также можно использовать стемминг для того, чтобы преобразовывать разные словоформы одного слова в один токен, но мы опустим этот момент.\n",
    "\n",
    "**Задание. Реализуйте функции get_token2idx и get_label2idx.** **<font color='red'>(1 балл)</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "IthnXKsoo7A3",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "token2cnt = Counter([token for sentence in train_token_seq for token in sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b_v8YUM7QELg",
    "outputId": "77f22cb2-a640-43e5-996b-fcaa2020ce99",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 8390),\n",
       " ('.', 7374),\n",
       " (',', 7290),\n",
       " ('of', 3815),\n",
       " ('in', 3621),\n",
       " ('to', 3424),\n",
       " ('a', 3199),\n",
       " ('and', 2872),\n",
       " ('(', 2861),\n",
       " (')', 2861)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2cnt.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MSm7B546nmDh",
    "outputId": "d6863a06-52a2-42da-859f-41097e761673",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных слов в тренировочном датасете: 21010\n",
      "Количество слов встречающихся только один раз в тренировочном датасете: 10060\n"
     ]
    }
   ],
   "source": [
    "print(f\"Количество уникальных слов в тренировочном датасете: {len(token2cnt)}\")\n",
    "print(f\"Количество слов встречающихся только один раз в тренировочном датасете: {len([token for token, cnt in token2cnt.items() if cnt == 1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRtCHt1QruSU"
   },
   "source": [
    "Как мы видим, у нас есть много слов, которые встречаются только один раз в датасете. Очевидно, что выучиться по ним у нас не получиться, мы только переобучимся, поэтому давайте выкинем такие слова при формировании нашего словаря."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "aCaPftCyQELi",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# используйте параметр min_count для того, чтобы отсекать слова частотой cnt < min_count\n",
    "\n",
    "def get_token2idx(\n",
    "    token2cnt: Dict[str, int],\n",
    "    min_count: int,\n",
    ") -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Get mapping from tokens to indices to use with Embedding layer.\n",
    "    \"\"\"\n",
    "\n",
    "    token2idx: Dict[str, int] = {}\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    token2idx = {'<PAD>': 0, '<UNK>': 1}\n",
    "    \n",
    "    token_len = len(token2idx)\n",
    "    for token, count in token2cnt.items():\n",
    "        if count >= min_count:\n",
    "            token2idx[token] = token_len\n",
    "            token_len += 1\n",
    "\n",
    "    return token2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uFK130y-sLH4",
    "outputId": "35f031b5-9388-48c4-8f8a-e77b5a3e580f",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "token2idx = get_token2idx(token2cnt, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "g69HFZC7QELh",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Функция для сортировки тегов, чтобы сначала был тег O, потом теги B- и только после теги I- (можно задать вручную)\n",
    "\n",
    "def sort_labels_func(x: str) -> int:\n",
    "    if x == \"O\":\n",
    "        return 0\n",
    "    elif x.startswith(\"B-\"):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "label_set = sorted(\n",
    "    set(label for sentence in train_label_seq for label in sentence),\n",
    "    key=lambda x: (sort_labels_func(x), x),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VI_3m4qbQELi",
    "outputId": "116bfcab-c56b-4ad9-b0f8-894ead418318",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-LOC', 'B-MISC', 'B-ORG', 'B-PER', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "t6i51GPtQELj",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_label2idx(label_set: List[str]) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Get mapping from labels to indices.\n",
    "    \"\"\"\n",
    "\n",
    "    label2idx: Dict[str, int] = {}\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    label_len = len(label2idx)\n",
    "    for label in label_set:\n",
    "        label2idx[label] = label_len\n",
    "        label_len += 1\n",
    "    return label2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XW6fK0HtQELk",
    "outputId": "17d18b48-55fa-4603-b342-e61409199577",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "label2idx = get_label2idx(label_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U13l-2IOQELk"
   },
   "source": [
    "Посмотрим на то, что мы получили:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O7U7bMrHQELl",
    "outputId": "53d80294-e80b-4536-acfa-99bf171d2e40",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PAD>\t0\n",
      "<UNK>\t1\n",
      "eu\t2\n",
      "german\t3\n",
      "call\t4\n",
      "to\t5\n",
      "boycott\t6\n",
      "british\t7\n",
      "lamb\t8\n",
      ".\t9\n"
     ]
    }
   ],
   "source": [
    "for token, idx in list(token2idx.items())[:10]:\n",
    "    print(f\"{token}\\t{idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hp75V-o2QELl",
    "outputId": "7f85dca1-eea6-4789-e261-1552bcaf91d4",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O\t0\n",
      "B-LOC\t1\n",
      "B-MISC\t2\n",
      "B-ORG\t3\n",
      "B-PER\t4\n",
      "I-LOC\t5\n",
      "I-MISC\t6\n",
      "I-ORG\t7\n",
      "I-PER\t8\n"
     ]
    }
   ],
   "source": [
    "for label, idx in label2idx.items():\n",
    "    print(f\"{label}\\t{idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VYb4BdAUhNzk",
    "outputId": "dc62e8d8-7b62-4638-c436-aaf657dc5287",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тесты пройдены!\n"
     ]
    }
   ],
   "source": [
    "assert len(get_token2idx(token2cnt, min_count=1)) == 21012, \"Ошибка в длине словаря, скорее всего неверно реализован min_count\"\n",
    "assert len(token2idx) == 10952, \"Неправильная длина token2idx, скорее всего неверно реализован min_count\"\n",
    "assert len(label2idx) == 9, \"Неправильная длина label2idx\"\n",
    "\n",
    "assert list(token2idx.items())[:10] == [('<PAD>', 0), ('<UNK>', 1), ('eu', 2), ('german', 3), ('call', 4), ('to', 5), ('boycott', 6), ('british', 7), ('lamb', 8), ('.', 9)], \"Неправильно сформированный token2idx\"\n",
    "assert label2idx == {'O': 0, 'B-LOC': 1, 'B-MISC': 2, 'B-ORG': 3, 'B-PER': 4, 'I-LOC': 5, 'I-MISC': 6, 'I-ORG': 7, 'I-PER': 8}, \"Неправильно сформированный label2idx\"\n",
    "\n",
    "print(\"Тесты пройдены!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItPs1DmOQELm"
   },
   "source": [
    "### Подготовка датасета и загрузчика\n",
    "\n",
    "Обычно нейронные сети обучаются батчами. Это означает, что каждое обновление весов нейронной сети происходит на основе нескольких последовательностей. Технической деталью является необходимость дополнить все последовательности внутри батча до одной длины.\n",
    "\n",
    "Из предыдущего практического задания вы должны знать о `Dataset`'е (`torch.utils.data.Dataset`) - структура данных, которая хранит и может по индексу отдавать данные для обучения. Датасет должен наследоваться от стандартного PyTorch класса Dataset и переопределять методы `__len__` и `__getitem__`.\n",
    "\n",
    "Метод `__getitem__` должен возвращать индексированную последовательность и её теги.\n",
    "\n",
    "**Не забудьте** про `<UNK>` спецтокен для неизвестных слов!\n",
    "    \n",
    "Давайте напишем кастомный датасет под нашу задачу, который на вход (метод `__init__`) будет принимать:\n",
    "- token_seq - список списков слов / токенов\n",
    "- label_seq - список списков тегов\n",
    "- token2idx\n",
    "- label2idx\n",
    "\n",
    "и возвращать из метода `__getitem__` два int64 тензора (`torch.LongTensor`) из индексов слов / токенов в сэмпле и индексов соответвующих тегов:\n",
    "\n",
    "**Задание. Реализуйте класс датасета NERDataset.** **<font color='red'>(1 балл)</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "kdZvnUUpQELm",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class NERDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for NER.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        token_seq: List[List[str]],\n",
    "        label_seq: List[List[str]],\n",
    "        token2idx: Dict[str, int],\n",
    "        label2idx: Dict[str, int],\n",
    "    ):\n",
    "        self.token2idx = token2idx\n",
    "        self.label2idx = label2idx\n",
    "\n",
    "        self.token_seq = [self.process_tokens(tokens, token2idx) for tokens in token_seq]\n",
    "        self.label_seq = [self.process_labels(labels, label2idx) for labels in label_seq]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_seq)\n",
    "\n",
    "    def __getitem__(\n",
    "        self,\n",
    "        idx: int,\n",
    "    ) -> Tuple[torch.LongTensor, torch.LongTensor]:\n",
    "        # YOUR CODE HERE\n",
    "        return torch.LongTensor(self.token_seq[idx]), torch.LongTensor(self.label_seq[idx])\n",
    "\n",
    "    @staticmethod\n",
    "    def process_tokens(\n",
    "        tokens: List[str],\n",
    "        token2idx: Dict[str, int],\n",
    "        unk: str = \"<UNK>\",\n",
    "    ) -> List[int]:\n",
    "        \"\"\"\n",
    "        Transform list of tokens into list of tokens' indices.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        result = []\n",
    "        for token in tokens:\n",
    "            result += [token2idx.get(token, token2idx.get(unk))]\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def process_labels(\n",
    "        labels: List[str],\n",
    "        label2idx: Dict[str, int],\n",
    "    ) -> List[int]:\n",
    "        \"\"\"\n",
    "        Transform list of labels into list of labels' indices.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        result = []\n",
    "        for label in labels:\n",
    "            result += [label2idx.get(label)]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCvaPJERQELn"
   },
   "source": [
    "Создадим три датасета:\n",
    "- *train_dataset*\n",
    "- *valid_dataset*\n",
    "- *test_dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "bUMsSNkoQELn",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = NERDataset(\n",
    "    token_seq=train_token_seq,\n",
    "    label_seq=train_label_seq,\n",
    "    token2idx=token2idx,\n",
    "    label2idx=label2idx,\n",
    ")\n",
    "valid_dataset = NERDataset(\n",
    "    token_seq=valid_token_seq,\n",
    "    label_seq=valid_label_seq,\n",
    "    token2idx=token2idx,\n",
    "    label2idx=label2idx,\n",
    ")\n",
    "test_dataset = NERDataset(\n",
    "    token_seq=test_token_seq,\n",
    "    label_seq=test_label_seq,\n",
    "    token2idx=token2idx,\n",
    "    label2idx=label2idx,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQIq1pAWQELo"
   },
   "source": [
    "Посмотрим на то, что мы получили:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q_Scync0QELo",
    "outputId": "1669dbf8-2b23-40e0-9012-430cd44c9bc4",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2, 1, 3, 4, 5, 6, 7, 8, 9]), tensor([3, 0, 2, 0, 0, 0, 2, 0, 0]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zyAazaLzjQ-K",
    "outputId": "ed864972-9051-4b85-e206-30e59d9971c8",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1737,  571, 1777,  197,  687,  145,  349,  111, 1819, 1558,    9]),\n",
       " tensor([0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NHuuh3YmjRNt",
    "outputId": "5f214ff3-7bbb-4b7c-8c9c-a861562b09cd",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1516,  571, 1434, 1729, 4893, 2014,   67,  310,  215, 3157, 3139,    9]),\n",
       " tensor([0, 0, 1, 0, 0, 0, 0, 4, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gox6uyF2idwZ",
    "outputId": "8abb0480-9913-4f8a-d50e-1713611cbc9b",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тесты пройдены!\n"
     ]
    }
   ],
   "source": [
    "assert len(train_dataset) == 14986, \"Неправильная длина train_dataset\"\n",
    "assert len(valid_dataset) == 3465, \"Неправильная длина valid_dataset\"\n",
    "assert len(test_dataset) == 3683, \"Неправильная длина test_dataset\"\n",
    "\n",
    "assert torch.equal(train_dataset[0][0], torch.tensor([2,1,3,4,5,6,7,8,9])), \"Неправильно сформированный train_dataset\"\n",
    "assert torch.equal(train_dataset[0][1], torch.tensor([3,0,2,0,0,0,2,0,0])), \"Неправильно сформированный train_dataset\"\n",
    "\n",
    "assert torch.equal(valid_dataset[0][0], torch.tensor([1737,571,1777,197,687,145,349,111,1819,1558,9])), \"Неправильно сформированный valid_dataset\"\n",
    "assert torch.equal(valid_dataset[0][1], torch.tensor([0,0,3,0,0,0,0,0,0,0,0])), \"Неправильно сформированный valid_dataset\"\n",
    "\n",
    "assert torch.equal(test_dataset[0][0], torch.tensor([1516,571,1434,1729,4893,2014,67,310,215,3157,3139,9])), \"Неправильно сформированный test_dataset\"\n",
    "assert torch.equal(test_dataset[0][1], torch.tensor([0,0,1,0,0,0,0,4,0,0,0,0])), \"Неправильно сформированный test_dataset\"\n",
    "\n",
    "print(\"Тесты пройдены!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWjJuAk7QELp"
   },
   "source": [
    "Для того, чтобы дополнять последовательности паддингом, будем использовать параметр `collate_fn` класса `DataLoader`.\n",
    "\n",
    "Принимая последовательность пар тензоров для предложений и тегов, необходимо дополнить все последовательности до последовательности максимальной длины в батче.\n",
    "\n",
    "Используйте для дополнения спецтокен `<PAD>` для последовательностей слов / токенов и -1 для последовательностей тегов.\n",
    "\n",
    "**hint**: удобно использовать метод **torch.nn.utils.rnn**. Обратите особое внимание на параметр *batch_first*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZiJVM5qQELp"
   },
   "source": [
    "`Collator` можно реализовать двумя способами:\n",
    "- класс с методом `__call__`\n",
    "- функцию\n",
    "\n",
    "Мы пойдем первым путем.\n",
    "\n",
    "Инициализировать экземпляр класса `Collator` (метод `__init__`) с помощью двух параметров:\n",
    "- id `<PAD>` спецтокена для последовательностей слов / токенов\n",
    "- id `<PAD>` спецтокена для последовательностей тегов (значение -1)\n",
    "\n",
    "Метод `__call__` на вход принимает батч, а именно список кортежей того, что нам возвращается из датасета. В нашем случае это список кортежей двух int64 тензоров - `List[Tuple[torch.LongTensor, torch.LongTensor]]`.\n",
    "\n",
    "На выходе мы хотим получить два тензора:\n",
    "- западденные индексы слов / токенов\n",
    "- западденные индексы тегов\n",
    "    \n",
    "P.S. `<PAD>` значение нужно для того, чтобы при подсчете лосса легко отличать западдированные токены от других. Можно использовать параметр *ignore_index* при инициализации лосса.\n",
    "\n",
    "**Задание. Реализуйте класс коллатора NERCollator.** **<font color='red'>(1 балл)</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "LNHNwoLnQELp",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class NERCollator:\n",
    "    \"\"\"\n",
    "    Collator that handles variable-size sentences.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        token_padding_value: int,\n",
    "        label_padding_value: int,\n",
    "    ):\n",
    "        self.token_padding_value = token_padding_value\n",
    "        self.label_padding_value = label_padding_value\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        batch: List[Tuple[torch.LongTensor, torch.LongTensor]],\n",
    "    ) -> Tuple[torch.LongTensor, torch.LongTensor]:\n",
    "\n",
    "        tokens, labels = zip(*batch)\n",
    "        tokens = torch.nn.utils.rnn.pad_sequence(tokens,\n",
    "                                               batch_first=True,\n",
    "                                               padding_value=self.token_padding_value)\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels,\n",
    "                                                batch_first=True,\n",
    "                                                padding_value=self.label_padding_value)\n",
    "        return tokens, labels\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "nZUMwVQTQELq",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "collator = NERCollator(\n",
    "    token_padding_value=token2idx[\"<PAD>\"],\n",
    "    label_padding_value=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jsgfij8WQELq"
   },
   "source": [
    "Теперь всё готово, чтобы задать `DataLoader`'ы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "gFljkiBOQELr",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    collate_fn=collator,\n",
    ")\n",
    "valid_dataloader = torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=1,  # для корректных замеров метрик оставить batch_size=1\n",
    "    shuffle=False, # для корректных замеров метрик оставить shuffle=False\n",
    "    collate_fn=collator,\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,  # для корректных замеров метрик оставить batch_size=1\n",
    "    shuffle=False, # для корректных замеров метрик оставить shuffle=False\n",
    "    collate_fn=collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i34wGJ4uQELr"
   },
   "source": [
    "Посмотрим на то, что мы получили:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "QLlr_DztQELr",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tokens, labels = next(iter(train_dataloader))\n",
    "\n",
    "tokens = tokens.to(device)\n",
    "labels = labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FdMMEDdbQELs",
    "outputId": "b7bd1bb5-248b-482c-cd5e-c98c6c3709f8",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 215, 2437,   67, 2585, 2586,   37, 2587, 2488, 2522,  282,  146, 2588,\n",
       "         2126,   80,  371,   14,  974, 2589,  184,  456,  511, 2014,   67, 1654,\n",
       "          687,   14, 2460, 2590,    9,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0],\n",
       "        [2392, 3851,   67, 2368,   37, 3855, 3856,   67, 1021,  414, 3857,   18,\n",
       "           19,   67,  732,    5,  707, 3858,  763,  746, 3007,  458, 3859, 3116,\n",
       "           54,   72,    5, 3075, 1599,   18,   73, 2850, 3071,  458,  467,  283,\n",
       "          746, 1709,    9]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w--fhADKQELs",
    "outputId": "708d1cec-7e0c-4f07-f723-900aab50203c",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  0,  4,  8,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  7,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  3,  7,  0, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1],\n",
       "        [ 2,  6,  0,  1,  0,  4,  8,  0,  0,  1,  5,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFeX0AYKlhGk",
    "outputId": "3c5a0193-2caf-4d7c-f02f-272b91e0f6f4",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тесты пройдены!\n"
     ]
    }
   ],
   "source": [
    "train_tokens, train_labels = next(iter(\n",
    "    torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=2,\n",
    "        shuffle=False,\n",
    "        collate_fn=collator,\n",
    "    )\n",
    "))\n",
    "assert torch.equal(train_tokens, torch.tensor([[ 2,  1,  3,  4,  5,  6,  7,  8,  9], [10, 11,  0,  0,  0,  0,  0,  0,  0]])), \"Похоже на ошибку в коллаторе\"\n",
    "assert torch.equal(train_labels, torch.tensor([[ 3,  0,  2,  0,  0,  0,  2,  0,  0], [ 4,  8, -1, -1, -1, -1, -1, -1, -1]])), \"Похоже на ошибку в коллаторе\"\n",
    "\n",
    "valid_tokens, valid_labels = next(iter(\n",
    "    torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=2,\n",
    "        shuffle=False,\n",
    "        collate_fn=collator,\n",
    "    )\n",
    "))\n",
    "assert torch.equal(valid_tokens, torch.tensor([[ 1737,   571,  1777,   197,   687,   145,   349,   111,  1819,  1558, 9], [  248, 10679,     0,     0,     0,     0,     0,     0,     0,     0,    0]])), \"Похоже на ошибку в коллаторе\"\n",
    "assert torch.equal(valid_labels, torch.tensor([[ 0,  0,  3,  0,  0,  0,  0,  0,  0,  0,  0], [ 1,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1]])), \"Похоже на ошибку в коллаторе\"\n",
    "\n",
    "test_tokens, test_labels = next(iter(\n",
    "    torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=2,\n",
    "        shuffle=False,\n",
    "        collate_fn=collator,\n",
    "    )\n",
    "))\n",
    "assert torch.equal(test_tokens, torch.tensor([[1516,  571, 1434, 1729, 4893, 2014,   67,  310,  215, 3157, 3139,    9], [   1,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]])), \"Похоже на ошибку в коллаторе\"\n",
    "assert torch.equal(test_labels, torch.tensor([[ 0,  0,  1,  0,  0,  0,  0,  4,  0,  0,  0,  0], [ 4,  8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]])), \"Похоже на ошибку в коллаторе\"\n",
    "\n",
    "print(\"Тесты пройдены!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Ul5gLriQELs"
   },
   "source": [
    "## Часть 2. BiLSTM-теггер (6 баллов)\n",
    "\n",
    "Определите архитектуру сети, используя библиотеку PyTorch. \n",
    "\n",
    "Ваша архитектура в этом пункте должна соответствовать стандартному теггеру:\n",
    "* Embedding слой на входе\n",
    "* LSTM (однонаправленный или двунаправленный)слой для обработки последовательности\n",
    "* Dropout (заданный отдельно или встроенный в LSTM) для уменьшения переобучения\n",
    "* Linear слой на выходе\n",
    "\n",
    "Для обучения сети используйте поэлементную кросс-энтропийную функцию потерь.\n",
    "\n",
    "**Обратите внимание**, что `<PAD>` токены не должны учавствовать в подсчёте функции потерь. В качестве оптимизатора рекомендуется использовать Adam. Для получения значений предсказаний по выходам модели используйте функцию `argmax`.\n",
    "\n",
    "**Задание. Реализуйте класс модели BiLSTM.** **<font color='red'>(2 балл)</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "uMiLQljZQELt",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class BiLSTM(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Bidirectional LSTM architecture.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_embeddings: int,\n",
    "        embedding_dim: int,\n",
    "        hidden_size: int,\n",
    "        num_layers: int,\n",
    "        dropout: float,\n",
    "        bidirectional: bool,\n",
    "        n_classes: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        if bidirectional:\n",
    "            self.head = torch.nn.Linear(hidden_size * 2, n_classes)\n",
    "        else:\n",
    "            self.head = torch.nn.Linear(hidden_size, n_classes)\n",
    "            \n",
    "        self.embedding = torch.nn.Embedding(\n",
    "            num_embeddings=num_embeddings,\n",
    "            embedding_dim=embedding_dim\n",
    "        )\n",
    "        \n",
    "        self.rnn = torch.nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "    def forward(self, tokens: torch.LongTensor) -> torch.Tensor:\n",
    "        embed = self.embedding(tokens)\n",
    "\n",
    "        # используем специальную функцию pack_padded_sequence для того, чтобы получить структуру PackedSequence\n",
    "        # которая не учитывать паддинг при проходе rnn\n",
    "        length = (tokens != 0).sum(dim=1).detach().cpu()\n",
    "        packed_embed = torch.nn.utils.rnn.pack_padded_sequence(\n",
    "            embed, length, batch_first=True, enforce_sorted=False\n",
    "          )\n",
    "        \n",
    "        # используем специальную функцию pad_packed_sequence для того, чтобы получить тензор из PackedSequence\n",
    "        packed_rnn_output, _ = self.rnn(packed_embed)\n",
    "        rnn_output, _ = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "            packed_rnn_output, batch_first=True)\n",
    "        \n",
    "        \n",
    "        logits = self.head(rnn_output)\n",
    "        return logits.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "zps8HL2VQELu",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = BiLSTM(\n",
    "    num_embeddings=len(token2idx),\n",
    "    embedding_dim=100,\n",
    "    hidden_size=100,\n",
    "    num_layers=1,\n",
    "    dropout=0.0,\n",
    "    bidirectional=True,\n",
    "    n_classes=len(label2idx),\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nmg2_C_oQELu",
    "outputId": "cc700776-3bbe-43a3-d0db-049ad74965e1",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM(\n",
       "  (head): Linear(in_features=200, out_features=9, bias=True)\n",
       "  (embedding): Embedding(10952, 100)\n",
       "  (rnn): LSTM(100, 100, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "sDvWB5J2QELv",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "Jn5Pu1UKQELv",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9, 39])\n"
     ]
    }
   ],
   "source": [
    "outputs = model(tokens)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n02Bsh8eQELw",
    "outputId": "6b704a7d-2cc9-49b0-a260-d4f6f52d2405",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [86], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize([\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m10\u001b[39m])\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m<\u001b[39m criterion(outputs, labels) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mТесты пройдены!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert outputs.shape == torch.Size([2, 9, 10])\n",
    "assert 2 < criterion(outputs, labels) < 3\n",
    "\n",
    "print(\"Тесты пройдены!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjhkK9QFQELu"
   },
   "source": [
    "### Эксперименты\n",
    "\n",
    "Проведите эксперименты на данных. Настраивайте параметры по валидационной выборке, не используя тестовую. Ваше цель — настроить сеть так, чтобы качество модели по F1-macro мере на валидационной и тестовой выборках было не меньше 0.76. \n",
    "\n",
    "Сделайте выводы о качестве модели, переобучении, чувствительности архитектуры к выбору гиперпараметров. Оформите результаты экспериментов в виде мини-отчета (в этом же ipython notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4hdrFZ9iRPi",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# создадим SummaryWriter для эксперимента с BiLSTMModel\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(log_dir=f\"logs/BiLSTMModel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruMTBSkQQELx"
   },
   "source": [
    "**Задание. Реализуйте функцию подсчета метрик compute_metrics.** **<font color='red'>(1 балл)</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xkpo3JgWQELx",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "def compute_metrics(\n",
    "    outputs: torch.Tensor,\n",
    "    labels: torch.LongTensor,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute NER metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    # Не забудюте отфильтровать <PAD> токен\n",
    "\n",
    "    # accuracy\n",
    "    accuracy = accuracy_score(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "    )\n",
    "\n",
    "    # precision\n",
    "    precision_micro = precision_score(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        average=\"micro\",\n",
    "        zero_division=0,\n",
    "    )\n",
    "    precision_macro = precision_score(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        average=\"macro\",\n",
    "        zero_division=0,\n",
    "    )\n",
    "    precision_weighted = precision_score(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        average=\"weighted\",\n",
    "        zero_division=0,\n",
    "    )\n",
    "\n",
    "    # recall\n",
    "    recall_micro = recall_score(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        average=\"micro\",\n",
    "        zero_division=0,\n",
    "        \n",
    "    )\n",
    "    recall_macro = recall_score(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        average=\"macro\",\n",
    "        zero_division=0,\n",
    "    )\n",
    "    recall_weighted = recall_score(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        average=\"weighted\",\n",
    "        zero_division=0,\n",
    "    )\n",
    "\n",
    "    # f1\n",
    "    f1_micro = f1_score(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        average=\"micro\",\n",
    "        zero_division=0,\n",
    "    )\n",
    "    f1_macro = f1_score(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        average=\"macro\",\n",
    "        zero_division=0,\n",
    "    )\n",
    "    f1_weighted = f1_score(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        average=\"weighted\",\n",
    "        zero_division=0,\n",
    "    )\n",
    "\n",
    "    metrics[\"accuracy\"] = accuracy\n",
    "\n",
    "    metrics[\"precision_micro\"]    = precision_micro\n",
    "    metrics[\"precision_macro\"]    = precision_macro\n",
    "    metrics[\"precision_weighted\"] = precision_weighted\n",
    "\n",
    "    metrics[\"recall_micro\"]    = recall_micro\n",
    "    metrics[\"recall_macro\"]    = recall_macro\n",
    "    metrics[\"recall_weighted\"] = recall_weighted\n",
    "\n",
    "    metrics[\"f1_micro\"]    = f1_micro\n",
    "    metrics[\"f1_macro\"]    = f1_macro\n",
    "    metrics[\"f1_weighted\"] = f1_weighted\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dzj89UygQEL0"
   },
   "source": [
    "**Задание. Реализуйте функции обучения и тестирования train_epoch и evaluate_epoch.** **<font color='red'>(2 балла)</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sG3vQbc_QEL0",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion: torch.nn.Module,\n",
    "    writer: SummaryWriter,\n",
    "    device: torch.device,\n",
    "    epoch: int,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    One training cycle (loop).\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = []\n",
    "    batch_metrics_list = defaultdict(list)\n",
    "\n",
    "    for i, (tokens, labels) in tqdm(\n",
    "        enumerate(dataloader),\n",
    "        total=len(dataloader),\n",
    "        desc=\"loop over train batches\",\n",
    "    ):\n",
    "\n",
    "        tokens, labels = tokens.to(device), labels.to(device)\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        # Подсчет лосса и шаг оптимизатора\n",
    "\n",
    "        epoch_loss.append(loss.item())\n",
    "        writer.add_scalar(\n",
    "            \"batch loss / train\", loss.item(), epoch * len(dataloader) + i\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            outputs_inference = model(tokens)\n",
    "            model.train()\n",
    "\n",
    "        batch_metrics = compute_metrics(\n",
    "            outputs=outputs_inference,\n",
    "            labels=labels,\n",
    "        )\n",
    "\n",
    "        for metric_name, metric_value in batch_metrics.items():\n",
    "            batch_metrics_list[metric_name].append(metric_value)\n",
    "            writer.add_scalar(\n",
    "                f\"batch {metric_name} / train\",\n",
    "                metric_value,\n",
    "                epoch * len(dataloader) + i,\n",
    "            )\n",
    "\n",
    "    avg_loss = np.mean(epoch_loss)\n",
    "    print(f\"Train loss: {avg_loss}\\n\")\n",
    "    writer.add_scalar(\"loss / train\", avg_loss, epoch)\n",
    "\n",
    "    for metric_name, metric_value_list in batch_metrics_list.items():\n",
    "        metric_value = np.mean(metric_value_list)\n",
    "        print(f\"Train {metric_name}: {metric_value}\\n\")\n",
    "        writer.add_scalar(f\"{metric_name} / train\", metric_value, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p4ztFogtQEL0",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_epoch(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    criterion: torch.nn.Module,\n",
    "    writer: SummaryWriter,\n",
    "    device: torch.device,\n",
    "    epoch: int,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    One evaluation cycle (loop).\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = []\n",
    "    batch_metrics_list = defaultdict(list)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, (tokens, labels) in tqdm(\n",
    "            enumerate(dataloader),\n",
    "            total=len(dataloader),\n",
    "            desc=\"loop over test batches\",\n",
    "        ):\n",
    "\n",
    "            tokens, labels = tokens.to(device), labels.to(device)\n",
    "\n",
    "            # YOUR CODE HERE\n",
    "            # Подсчет лосса\n",
    "\n",
    "            epoch_loss.append(loss.item())\n",
    "            writer.add_scalar(\n",
    "                \"batch loss / test\", loss.item(), epoch * len(dataloader) + i\n",
    "            )\n",
    "\n",
    "            batch_metrics = compute_metrics(\n",
    "                outputs=outputs,\n",
    "                labels=labels,\n",
    "            )\n",
    "\n",
    "            for metric_name, metric_value in batch_metrics.items():\n",
    "                batch_metrics_list[metric_name].append(metric_value)\n",
    "                writer.add_scalar(\n",
    "                    f\"batch {metric_name} / test\",\n",
    "                    metric_value,\n",
    "                    epoch * len(dataloader) + i,\n",
    "                )\n",
    "\n",
    "        avg_loss = np.mean(epoch_loss)\n",
    "        print(f\"Test loss:  {avg_loss}\\n\")\n",
    "        writer.add_scalar(\"loss / test\", avg_loss, epoch)\n",
    "\n",
    "        for metric_name, metric_value_list in batch_metrics_list.items():\n",
    "            metric_value = np.mean(metric_value_list)\n",
    "            print(f\"Test {metric_name}: {metric_value}\\n\")\n",
    "            writer.add_scalar(f\"{metric_name} / test\", np.mean(metric_value), epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z7Z5MTNzQEL1",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    n_epochs: int,\n",
    "    model: torch.nn.Module,\n",
    "    train_dataloader: torch.utils.data.DataLoader,\n",
    "    test_dataloader: torch.utils.data.DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion: torch.nn.Module,\n",
    "    writer: SummaryWriter,\n",
    "    device: torch.device,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Training loop.\n",
    "    \"\"\"\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        print(f\"Epoch [{epoch+1} / {n_epochs}]\\n\")\n",
    "\n",
    "        train_epoch(\n",
    "            model=model,\n",
    "            dataloader=train_dataloader,\n",
    "            optimizer=optimizer,\n",
    "            criterion=criterion,\n",
    "            writer=writer,\n",
    "            device=device,\n",
    "            epoch=epoch,\n",
    "        )\n",
    "        evaluate_epoch(\n",
    "            model=model,\n",
    "            dataloader=test_dataloader,\n",
    "            criterion=criterion,\n",
    "            writer=writer,\n",
    "            device=device,\n",
    "            epoch=epoch,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTxfU0BfQEL1"
   },
   "source": [
    "**Задание. Проведите эксперименты.** **<font color='red'>(2 балла)</font>**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yz6mjGZUQEL2",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H8R6nopyQEL-"
   },
   "source": [
    "## Часть 3. Transformers-теггер (6 баллов)\n",
    "\n",
    "В данной части задания нужно сделать все то же самое, но с использованием модели на базе архитектуры Transformer, а именно предлагается дообучать предобученную модель **BERT**.\n",
    "\n",
    "Для данной модели подразумевается специальная подготовка данных, с чего мы и начнем:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SrbX5gFDQEL-"
   },
   "source": [
    "Модель **BERT** использует специальный токенизатор WordPiece для разбиения предложений на токены. Готовая предобученная версия такого токенизатора существует в библиотеке **transformers**. Есть два класса: `BertTokenizer` и `BertTokenizerFast`. Использовать можно любой, но второй вариант работает существенно быстрее.\n",
    "\n",
    "Токенизаторы можно обучать с нуля на своем корпусе данных, а можно подгружать уже готовые. Готовые токенизаторы, как правило, соответствуют предобученной конфигурации модели, которая использует словарь из этого токенизатора. \n",
    "\n",
    "Мы будем использовать базовую конфигурацию предобученного **BERT** для модели и токенизатора.\n",
    "\n",
    "P.S. Часто приходится проводить эксперименты с моделями разной архитектуры, например **BERT** и **GPT**, поэтому удобно использовать класс `AutoTokenizer`, который по названию модели сам определит, какой класс нужен для инициализации токенизатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4-UTiI4gQEL-",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kSbBhvnDQEMA",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"distilbert-base-cased\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxWNX5i6QEMA"
   },
   "source": [
    "Подгружение предобученных моделей и токенизаторов в **huggingface** происходит с помощью конструктора **from_pretrained**.\n",
    "\n",
    "В данном конструкторе можно указать либо путь к предобученному токенизатору, либо название предобученной конфигурации, как в нашем случае: тогда **transformers** сам подгрузит нужные параметры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3tg_bCeaQEMA",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MIrbmNoQEMA"
   },
   "source": [
    "### Подготовка словарей\n",
    "\n",
    "В сравнении с рекуррентными моделями, на больше не нужно заниматься сборкой словаря, так как это уже сделано заранее благодаря токенизаторам и алгоритмам, стоящими за ними.\n",
    "\n",
    "Но нам как и прежде потребуется:\n",
    "- {**label**}→{**label_idx**}: соответствие между тегом и уникальным индексом (начинается с 0);\n",
    "\n",
    "Но данное отображение у нас уже реализовано в одной из предыдущих частей задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvYF-4uaQEMB"
   },
   "source": [
    "### Подготовка датасета и загрузчика\n",
    "\n",
    "Мы также хотим обучать модель батчами, поэтому нам как и прежде понадобятся `Dataset`, `Collator` и `DataLoader`.\n",
    "\n",
    "Но мы не можем переиспользовать те, что в предыдущих частях задания, так как обработка данных должна производится немного иначе с использованием токенизатора.\n",
    "\n",
    "Давайте напишем новый кастомный датасет, который на вход (метод `__init__`) будет принимать:\n",
    "- token_seq - список списков слов / токенов\n",
    "- label_seq - список списков тегов\n",
    "\n",
    "и возвращать из метода `__getitem__` два списка:\n",
    "- список текстовых значений (`List[str]`) из индексов токенов в сэмпле\n",
    "- список целочисленных значений (`List[int]`) из индексов соответвующих тегов\n",
    "\n",
    "P.S. В отличие от предыдущего кастомного датасет, здесь мы возвращаем два `List`'а вместо `torch.LongTensor`, так как логику формирования западдированного батча мы перенесем в `Collator` из-за специфики работы токенизатора - он сам возвращает уже западдированный тензор с индексами токенов, а для индексов тегов нам нужно будет сделать это самостоятельно по аналогии с предыдущим датасетом.\n",
    "\n",
    "**Задание. Реализуйте класс датасета TransformersDataset.** **<font color='red'>(1 балл)</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7EoNLDOOQEMB",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class TransformersDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Transformers Dataset for NER.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        token_seq: List[List[str]],\n",
    "        label_seq: List[List[str]],\n",
    "    ):\n",
    "        self.token_seq = token_seq\n",
    "        self.label_seq = [self.process_labels(labels, label2idx) for labels in label_seq]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_seq)\n",
    "\n",
    "    def __getitem__(\n",
    "        self,\n",
    "        idx: int,\n",
    "    ) -> Tuple[List[str], List[int]]:\n",
    "        # YOUR CODE HERE\n",
    "    \n",
    "    @staticmethod\n",
    "    def process_labels(\n",
    "        labels: List[str],\n",
    "        label2idx: Dict[str, int],\n",
    "    ) -> List[int]:\n",
    "        \"\"\"\n",
    "        Transform list of labels into list of labels' indices.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1oNc-31QEMB"
   },
   "source": [
    "Создадим три датасета:\n",
    "- *train_dataset*\n",
    "- *valid_dataset*\n",
    "- *test_dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vqg56Jf8QEMC",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = TransformersDataset(\n",
    "    token_seq=train_token_seq,\n",
    "    label_seq=train_label_seq,\n",
    ")\n",
    "valid_dataset = TransformersDataset(\n",
    "    token_seq=valid_token_seq,\n",
    "    label_seq=valid_label_seq,\n",
    ")\n",
    "test_dataset = TransformersDataset(\n",
    "    token_seq=test_token_seq,\n",
    "    label_seq=test_label_seq,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WdIS6XrvQEMC"
   },
   "source": [
    "Посмотрим на то, что мы получили:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IT00Pjy6QEMC",
    "outputId": "6bb42a27-08f0-49f5-96f5-52573a1a75af",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uYal2icQmuD-",
    "outputId": "572bab3f-d53d-46d2-dd6f-367042966062",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "valid_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FCXd3FWVmuKe",
    "outputId": "e35bfbaf-340f-4fba-cc39-fa84ce632cda",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B4R605vAnYT9",
    "outputId": "1b6542ed-4520-4093-dddf-f9404e059917",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "assert len(train_dataset) == 14986, \"Неправильная длина train_dataset\"\n",
    "assert len(valid_dataset) == 3465, \"Неправильная длина valid_dataset\"\n",
    "assert len(test_dataset) == 3683, \"Неправильная длина test_dataset\"\n",
    "\n",
    "assert train_dataset[0][0] == ['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.'], \"Неправильно сформированный train_dataset\"\n",
    "assert train_dataset[0][1] == [3,0,2,0,0,0,2,0,0], \"Неправильно сформированный train_dataset\"\n",
    "\n",
    "assert valid_dataset[0][0] == ['cricket', '-', 'leicestershire', 'take', 'over', 'at', 'top', 'after', 'innings', 'victory', '.'], \"Неправильно сформированный valid_dataset\"\n",
    "assert valid_dataset[0][1] == [0,0,3,0,0,0,0,0,0,0,0], \"Неправильно сформированный valid_dataset\"\n",
    "\n",
    "assert test_dataset[0][0] == ['soccer', '-', 'japan', 'get', 'lucky', 'win', ',', 'china', 'in', 'surprise', 'defeat', '.'], \"Неправильно сформированный test_dataset\"\n",
    "assert test_dataset[0][1] == [0,0,1,0,0,0,0,4,0,0,0,0], \"Неправильно сформированный test_dataset\"\n",
    "\n",
    "print(\"Тесты пройдены!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zP_6iQnQEMC"
   },
   "source": [
    "Реализуем новый `Collator`.\n",
    "\n",
    "Инициализировать коллатор будет 3 аргументами:\n",
    "- токенизатор\n",
    "- параметры токенизатора в виде словаря (затем используем как `**kwargs`)\n",
    "- id спецтокена для последовательностей тегов (значение -1)\n",
    "\n",
    "Метод `__call__` на вход принимает батч, а именно список кортежей того, что нам возвращается из датасета. В нашем случае это список кортежей двух int64 тензоров - `List[Tuple[torch.LongTensor, torch.LongTensor]]`.\n",
    "\n",
    "На выходе мы хотим получить два тензора:\n",
    "- западденные индексы слов / токенов\n",
    "- западденные индексы тегов\n",
    "\n",
    "**Задание. Реализуйте класс коллатора TransformersCollator.** **<font color='red'>(2 балла)</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BonAp65jQEMD",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizer\n",
    "from transformers.tokenization_utils_base import BatchEncoding\n",
    "\n",
    "\n",
    "class TransformersCollator:\n",
    "    \"\"\"\n",
    "    Transformers Collator that handles variable-size sentences.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer: PreTrainedTokenizer,\n",
    "        tokenizer_kwargs: Dict[str, Any],\n",
    "        label_padding_value: int,\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokenizer_kwargs = tokenizer_kwargs\n",
    "        \n",
    "        self.label_padding_value = label_padding_value\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        batch: List[Tuple[List[str], List[int]]],\n",
    "    ) -> Tuple[torch.LongTensor, torch.LongTensor]:\n",
    "        tokens, labels = zip(*batch)\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        tokens.pop(\"offset_mapping\")\n",
    "\n",
    "        return tokens, labels\n",
    "    \n",
    "    @staticmethod\n",
    "    def encode_labels(\n",
    "        tokens: BatchEncoding,\n",
    "        labels: List[List[int]],\n",
    "        label_padding_value: int,\n",
    "    ) -> torch.LongTensor:\n",
    "\n",
    "        encoded_labels = []\n",
    "\n",
    "        for doc_labels, doc_offset in zip(labels, tokens.offset_mapping):\n",
    "\n",
    "            doc_enc_labels = np.ones(len(doc_offset), dtype=int) * label_padding_value\n",
    "            arr_offset = np.array(doc_offset)\n",
    "\n",
    "            doc_enc_labels[(arr_offset[:,0] == 0) & (arr_offset[:,1] != 0)] = doc_labels\n",
    "            encoded_labels.append(doc_enc_labels.tolist())\n",
    "\n",
    "        return torch.LongTensor(encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iC8JkUPnQEMD",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tokenizer_kwargs = {\n",
    "    \"is_split_into_words\":    True,\n",
    "    \"return_offsets_mapping\": True,\n",
    "    \"padding\":                True,\n",
    "    \"truncation\":             True,\n",
    "    \"max_length\":             512,\n",
    "    \"return_tensors\":         \"pt\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5sCDaxR6QEMD",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "collator = TransformersCollator(\n",
    "    tokenizer=tokenizer,\n",
    "    tokenizer_kwargs=tokenizer_kwargs,\n",
    "    label_padding_value=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eirev0N_QEMD"
   },
   "source": [
    "Теперь всё готово, чтобы задать `DataLoader`'ы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9JDrLC6pQEME",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    collate_fn=collator,\n",
    ")\n",
    "valid_dataloader = torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=1,  # для корректных замеров метрик оставить batch_size=1\n",
    "    shuffle=False, # для корректных замеров метрик оставить shuffle=False\n",
    "    collate_fn=collator,\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,  # для корректных замеров метрик оставить batch_size=1\n",
    "    shuffle=False, # для корректных замеров метрик оставить shuffle=False\n",
    "    collate_fn=collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3zGjEDHQEME"
   },
   "source": [
    "Посмотрим на то, что мы получили:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KSWcYEAWQEME",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tokens, labels = next(iter(train_dataloader))\n",
    "\n",
    "tokens = tokens.to(device)\n",
    "labels = labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NTcdU1BlQEME",
    "outputId": "94ac83e6-a90e-4247-a8c9-46fb487d6d91",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p7ZTh97-QEME",
    "outputId": "7eb951ed-2bf6-475a-f799-07551fc3b5c0",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pMprtk9bodM9",
    "outputId": "d93f5b97-fbad-4538-f37f-068c7bbac104",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_tokens, train_labels = next(iter(\n",
    "    torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=2,\n",
    "        shuffle=False,\n",
    "        collate_fn=collator,\n",
    "    )\n",
    "))\n",
    "assert torch.equal(train_tokens['input_ids'], torch.tensor([[  101,   174,  1358, 22961,   176, 14170,  1840,  1106, 21423,  9304, 10721,  1324,  2495, 12913,   119,   102], [  101, 11109,  1200,  1602,  6715,   102,     0,     0,     0,     0,    0,     0,     0,     0,     0,     0]])), \"Похоже на ошибку в коллаторе\"\n",
    "assert torch.equal(train_tokens['attention_mask'], torch.tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])), \"Похоже на ошибку в коллаторе\"\n",
    "assert torch.equal(train_labels, torch.tensor([[-1,  3, -1,  0,  2, -1,  0,  0,  0,  2, -1, -1,  0, -1,  0, -1], [-1,  4, -1,  8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]])), \"Похоже на ошибку в коллаторе\"\n",
    "\n",
    "valid_tokens, valid_labels = next(iter(\n",
    "    torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=2,\n",
    "        shuffle=False,\n",
    "        collate_fn=collator,\n",
    "    )\n",
    "))\n",
    "assert torch.equal(valid_tokens['input_ids'], torch.tensor([[  101,  5428,   118,  5837, 18117,  5759, 15189,  1321,  1166,  1120,  1499,  1170,  6687,  2681,   119,   102], [  101, 25338, 17996,  1820,   118,  4775,   118,  1476,   102,     0,     0,     0,     0,     0,     0,     0]])), \"Похоже на ошибку в коллаторе\"\n",
    "assert torch.equal(valid_tokens['attention_mask'], torch.tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]])), \"Похоже на ошибку в коллаторе\"\n",
    "assert torch.equal(valid_labels, torch.tensor([[-1,  0,  0,  3, -1, -1, -1,  0,  0,  0,  0,  0,  0,  0,  0, -1], [-1,  1, -1,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]])), \"Похоже на ошибку в коллаторе\"\n",
    "\n",
    "test_tokens, test_labels = next(iter(\n",
    "    torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=2,\n",
    "        shuffle=False,\n",
    "        collate_fn=collator,\n",
    "    )\n",
    "))\n",
    "assert torch.equal(test_tokens['input_ids'], torch.tensor([[  101,  5862,   118,   179, 26519,  1179,  1243,  6918,  1782,   117,  5144,  1161,  1107,  3774,  3326,   119,   102], [  101,  9468,  3309,  1306, 19122,  2293,   102,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])), \"Похоже на ошибку в коллаторе\"\n",
    "assert torch.equal(test_tokens['attention_mask'], torch.tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])), \"Похоже на ошибку в коллаторе\"\n",
    "assert torch.equal(test_labels, torch.tensor([[-1,  0,  0,  1, -1, -1,  0,  0,  0,  0,  4, -1,  0,  0,  0,  0, -1], [-1,  4, -1, -1,  8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]])), \"Похоже на ошибку в коллаторе\"\n",
    "\n",
    "print(\"Тесты пройдены!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_m-taH0SQEMF"
   },
   "source": [
    "В библиотеке **transformers** есть классы для модели BERT, уже настроенные под решение конкретных задач, с соответствующими головами классификации. Для задачи NER будем использовать класс `BertForTokenClassification`.\n",
    "\n",
    "По аналогии с токенизаторами, мы можем использовать класс `AutoModelForTokenClassification`, который по названию модели сам определит, какой класс нужен для инициализации модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x6tq_i7JQEMF",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vma9yj0zQEMF",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(label2idx),\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Imv-6gAQQEMG",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LAdHfn4oQEMG",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "outputs = model(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P-kTke_8QEMG",
    "outputId": "d3ccee80-a0c4-429a-8d62-787faf8543d2",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "assert 2 < criterion(outputs[\"logits\"].transpose(1, 2), labels) < 3\n",
    "\n",
    "print(\"Тесты пройдены!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Ana4qGKeHrN",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# создадим SummaryWriter для эксперимента с BiLSTMModel\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(log_dir=f\"logs/Transformer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sNuFPRdQEMH"
   },
   "source": [
    "### Эксперименты\n",
    "\n",
    "Проведите эксперименты на данных. Настраивайте параметры по валидационной выборке, не используя тестовую. Ваше цель — настроить сеть так, чтобы качество модели по F1-macro мере на валидационной и тестовой выборках было не меньше 0.9. \n",
    "\n",
    "Сделайте выводы о качестве модели, переобучении, чувствительности архитектуры к выбору гиперпараметров. Оформите результаты экспериментов в виде мини-отчета (в этом же ipython notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7IfkN20lrN0J"
   },
   "source": [
    "Вы можете использовать ту же самую функцию train, что и до этого за тем исключением, что вместо инференса `model(tokens)` нужно делать `model(**tokens)`, а вместо `outputs` использовать `outputs[\"logits\"].transpose(1, 2)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8iyZUFddzYE5"
   },
   "source": [
    "**Задание. Проведите эксперименты.** **<font color='red'>(2 балла)</font>**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iv92wK5P7pjl",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XlI3cb1QEL2"
   },
   "source": [
    "## Часть 4 - Бонус. BiLSTMAttention-теггер (2 баллa)\n",
    "\n",
    "Необходимо провести те же самые эксперименты как и в части 2, но уже с использованием усовершенствованной архитектуры теггера BiLSTM с Attention механизмом.\n",
    "\n",
    "**Обратите внимание**, что реализовывать Attention самому не нужно, можно использовать `torch.nn.MultiheadAttention`.\n",
    "\n",
    "Также сделайте выводы о качестве модели, переобучении, чувствительности архитектуры к выбору гиперпараметров и проведите небольшой сравнительный анализ с предыдущей архитектурой. Оформите результаты экспериментов в виде мини-отчета (в этом же ipython notebook).\n",
    "\n",
    "**Задание. Реализуйте класс модели BiLSTMAttn.** **<font color='red'>(1 балл)</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_MyLQp047yID",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezh9kLTkQEL9"
   },
   "source": [
    "**Задание. Проведите эксперименты и побейте метрику из части 2.** **<font color='red'>(1 балл)</font>**\n",
    "\n",
    "P.S. Eсли качества увеличить не получилось, это нужно обосновать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sE1C1tzEQEL-",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "4MIrbmNoQEMA"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "8d4ce941904148077feb793883e611d25d231ca995d9164b22ee99fd0facd8d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
